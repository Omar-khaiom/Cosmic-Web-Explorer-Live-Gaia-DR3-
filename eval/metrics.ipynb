{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2023e074",
   "metadata": {},
   "source": [
    "# Galaxy Visualization Metrics Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis tools for evaluating the performance and quality of the galaxy visualization system. It includes metrics for rendering performance, data processing efficiency, and visualization quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d7e72",
   "metadata": {},
   "source": [
    "## Data Loading and Configuration\n",
    "\n",
    "Load benchmark data and configure analysis parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "config = {\n",
    "    'data_dir': '../data',\n",
    "    'benchmark_results_dir': './benchmark_results',\n",
    "    'figures_dir': '../docs/figures',\n",
    "    'target_fps': 60,\n",
    "    'acceptable_fps': 30,\n",
    "    'lod_levels': [0, 1, 2]\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in config.values():\n",
    "    if isinstance(dir_path, str) and 'dir' in dir_path.lower():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Load sample benchmark data (simulated for demonstration)\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample benchmark data for analysis\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate FPS data for different LOD levels\n",
    "    lod_data = {}\n",
    "    for lod in config['lod_levels']:\n",
    "        base_fps = 80 - (lod * 15)  # Higher LOD = lower FPS\n",
    "        fps_data = np.random.normal(base_fps, 5, 1000)\n",
    "        fps_data = np.clip(fps_data, 10, 120)  # Reasonable FPS range\n",
    "        \n",
    "        lod_data[f'lod_{lod}'] = {\n",
    "            'fps': fps_data,\n",
    "            'frame_time': 1000 / fps_data,  # Convert to milliseconds\n",
    "            'point_count': np.random.randint(10000, 100000 - (lod * 30000), 1000),\n",
    "            'memory_usage': np.random.normal(256 - (lod * 50), 20, 1000)\n",
    "        }\n",
    "    \n",
    "    return lod_data\n",
    "\n",
    "sample_data = generate_sample_data()\n",
    "print(\"Sample benchmark data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136f7be",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze rendering performance metrics across different LOD levels and scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22972bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis functions\n",
    "def analyze_fps_performance(data):\n",
    "    \"\"\"Analyze FPS performance across LOD levels\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for lod_key, lod_data in data.items():\n",
    "        fps_values = lod_data['fps']\n",
    "        \n",
    "        results[lod_key] = {\n",
    "            'mean_fps': np.mean(fps_values),\n",
    "            'median_fps': np.median(fps_values),\n",
    "            'std_fps': np.std(fps_values),\n",
    "            'min_fps': np.min(fps_values),\n",
    "            'max_fps': np.max(fps_values),\n",
    "            'p95_fps': np.percentile(fps_values, 95),\n",
    "            'p99_fps': np.percentile(fps_values, 99),\n",
    "            'target_fps_percentage': np.sum(fps_values >= config['target_fps']) / len(fps_values) * 100,\n",
    "            'acceptable_fps_percentage': np.sum(fps_values >= config['acceptable_fps']) / len(fps_values) * 100\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_performance_summary(results):\n",
    "    \"\"\"Create a summary DataFrame of performance results\"\"\"\n",
    "    df = pd.DataFrame(results).T\n",
    "    df.index.name = 'LOD Level'\n",
    "    return df.round(2)\n",
    "\n",
    "# Analyze performance\n",
    "performance_results = analyze_fps_performance(sample_data)\n",
    "performance_summary = create_performance_summary(performance_results)\n",
    "\n",
    "print(\"Performance Analysis Summary:\")\n",
    "print(performance_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ffdf02",
   "metadata": {},
   "source": [
    "## Interactive Visualizations\n",
    "\n",
    "Create interactive plots for exploring performance metrics and visualization quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f040ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive performance plots\n",
    "def create_fps_comparison_plot(data):\n",
    "    \"\"\"Create an interactive FPS comparison plot\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('FPS Distribution', 'Frame Time Distribution', \n",
    "                       'FPS vs Point Count', 'Memory Usage'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    \n",
    "    for i, (lod_key, lod_data) in enumerate(data.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        lod_label = f'LOD {lod_key.split(\"_\")[1]}'\n",
    "        \n",
    "        # FPS histogram\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=lod_data['fps'], name=f'{lod_label} FPS', \n",
    "                        marker_color=color, opacity=0.7),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Frame time histogram\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=lod_data['frame_time'], name=f'{lod_label} Frame Time',\n",
    "                        marker_color=color, opacity=0.7, showlegend=False),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # FPS vs Point Count scatter\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=lod_data['point_count'], y=lod_data['fps'],\n",
    "                      mode='markers', name=f'{lod_label} Performance',\n",
    "                      marker=dict(color=color, size=3, opacity=0.6),\n",
    "                      showlegend=False),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Memory usage over time\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=list(range(len(lod_data['memory_usage']))), \n",
    "                      y=lod_data['memory_usage'],\n",
    "                      mode='lines', name=f'{lod_label} Memory',\n",
    "                      line=dict(color=color), showlegend=False),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Galaxy Visualization Performance Metrics\",\n",
    "        showlegend=True,\n",
    "        height=800,\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "    \n",
    "    # Update axis labels\n",
    "    fig.update_xaxes(title_text=\"FPS\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Frame Time (ms)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Point Count\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"FPS\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Memory (MB)\", row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display the interactive plot\n",
    "fps_plot = create_fps_comparison_plot(sample_data)\n",
    "fps_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073878b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "config = {\n",
    "    'data_dir': '../data',\n",
    "    'benchmark_results_dir': './benchmark_results',\n",
    "    'figures_dir': '../docs/figures',\n",
    "    'target_fps': 60,\n",
    "    'acceptable_fps': 30,\n",
    "    'lod_levels': [0, 1, 2]\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in config.values():\n",
    "    if isinstance(dir_path, str) and 'dir' in dir_path.lower():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Load sample benchmark data (simulated for demonstration)\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample benchmark data for analysis\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate FPS data for different LOD levels\n",
    "    lod_data = {}\n",
    "    for lod in config['lod_levels']:\n",
    "        base_fps = 80 - (lod * 15)  # Higher LOD = lower FPS\n",
    "        fps_data = np.random.normal(base_fps, 5, 1000)\n",
    "        fps_data = np.clip(fps_data, 10, 120)  # Reasonable FPS range\n",
    "        \n",
    "        lod_data[f'lod_{lod}'] = {\n",
    "            'fps': fps_data,\n",
    "            'frame_time': 1000 / fps_data,  # Convert to milliseconds\n",
    "            'point_count': np.random.randint(10000, 100000 - (lod * 30000), 1000),\n",
    "            'memory_usage': np.random.normal(256 - (lod * 50), 20, 1000)\n",
    "        }\n",
    "    \n",
    "    return lod_data\n",
    "\n",
    "sample_data = generate_sample_data()\n",
    "print(\"Sample benchmark data generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ef3e3",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Analyze rendering performance across different LOD levels and scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2210af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis functions\n",
    "class PerformanceAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.results = {}\n",
    "    \n",
    "    def analyze_fps_distribution(self):\n",
    "        \"\"\"Analyze FPS distribution across LOD levels\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        fig.suptitle('FPS Distribution by LOD Level', fontsize=16, color='white')\n",
    "        \n",
    "        for i, lod in enumerate(config['lod_levels']):\n",
    "            lod_key = f'lod_{lod}'\n",
    "            fps_data = self.data[lod_key]['fps']\n",
    "            \n",
    "            axes[i].hist(fps_data, bins=30, alpha=0.7, color=plt.cm.viridis(i/3))\n",
    "            axes[i].set_title(f'LOD {lod}', color='white')\n",
    "            axes[i].set_xlabel('FPS', color='white')\n",
    "            axes[i].set_ylabel('Frequency', color='white')\n",
    "            axes[i].axvline(config['target_fps'], color='red', linestyle='--', label='Target FPS')\n",
    "            axes[i].axvline(config['acceptable_fps'], color='orange', linestyle='--', label='Min Acceptable')\n",
    "            axes[i].legend()\n",
    "            axes[i].tick_params(colors='white')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        for lod in config['lod_levels']:\n",
    "            lod_key = f'lod_{lod}'\n",
    "            fps_data = self.data[lod_key]['fps']\n",
    "            \n",
    "            self.results[f'{lod_key}_fps_stats'] = {\n",
    "                'mean': np.mean(fps_data),\n",
    "                'median': np.median(fps_data),\n",
    "                'std': np.std(fps_data),\n",
    "                'p95': np.percentile(fps_data, 95),\n",
    "                'p99': np.percentile(fps_data, 99),\n",
    "                'target_compliance': np.mean(fps_data >= config['target_fps']) * 100,\n",
    "                'acceptable_compliance': np.mean(fps_data >= config['acceptable_fps']) * 100\n",
    "            }\n",
    "    \n",
    "    def analyze_performance_tradeoffs(self):\n",
    "        \"\"\"Analyze performance vs quality tradeoffs\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['FPS vs Point Count', 'Memory Usage vs LOD', 'Frame Time Distribution', 'Performance Summary'],\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"type\": \"table\"}]]\n",
    "        )\n",
    "        \n",
    "        colors = ['red', 'green', 'blue']\n",
    "        \n",
    "        for i, lod in enumerate(config['lod_levels']):\n",
    "            lod_key = f'lod_{lod}'\n",
    "            data = self.data[lod_key]\n",
    "            \n",
    "            # FPS vs Point Count scatter\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data['point_count'][:100],  # Sample for visibility\n",
    "                    y=data['fps'][:100],\n",
    "                    mode='markers',\n",
    "                    name=f'LOD {lod}',\n",
    "                    marker=dict(color=colors[i], alpha=0.6)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Memory usage box plot\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=data['memory_usage'],\n",
    "                    name=f'LOD {lod}',\n",
    "                    marker_color=colors[i]\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            \n",
    "            # Frame time histogram\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=data['frame_time'],\n",
    "                    name=f'LOD {lod}',\n",
    "                    opacity=0.7,\n",
    "                    marker_color=colors[i]\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # Summary table\n",
    "        summary_data = []\n",
    "        for lod in config['lod_levels']:\n",
    "            lod_key = f'lod_{lod}'\n",
    "            stats = self.results.get(f'{lod_key}_fps_stats', {})\n",
    "            summary_data.append([\n",
    "                f'LOD {lod}',\n",
    "                f\"{stats.get('mean', 0):.1f}\",\n",
    "                f\"{stats.get('p95', 0):.1f}\",\n",
    "                f\"{stats.get('target_compliance', 0):.1f}%\"\n",
    "            ])\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Table(\n",
    "                header=dict(values=['LOD Level', 'Avg FPS', 'P95 FPS', 'Target Compliance']),\n",
    "                cells=dict(values=list(zip(*summary_data)))\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=True, title_text=\"Performance Analysis Dashboard\")\n",
    "        fig.show()\n",
    "\n",
    "# Create analyzer and run analysis\n",
    "analyzer = PerformanceAnalyzer(sample_data)\n",
    "analyzer.analyze_fps_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1454ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run performance tradeoffs analysis\n",
    "analyzer.analyze_performance_tradeoffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e3e92",
   "metadata": {},
   "source": [
    "## Visualization Quality Metrics\n",
    "\n",
    "Evaluate the quality and accuracy of the galaxy visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization quality assessment\n",
    "class QualityAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def simulate_quality_metrics(self):\n",
    "        \"\"\"Simulate visualization quality metrics\"\"\"\n",
    "        # Simulate different quality aspects\n",
    "        quality_data = {\n",
    "            'spatial_accuracy': np.random.normal(0.95, 0.02, 100),  # How accurately positions are represented\n",
    "            'color_consistency': np.random.normal(0.92, 0.03, 100),  # Color mapping consistency\n",
    "            'lod_transition_smoothness': np.random.normal(0.88, 0.05, 100),  # Smoothness of LOD transitions\n",
    "            'occlusion_handling': np.random.normal(0.85, 0.04, 100),  # How well occlusion is handled\n",
    "            'visual_completeness': np.random.normal(0.91, 0.03, 100)  # Completeness of visualization\n",
    "        }\n",
    "        \n",
    "        return quality_data\n",
    "    \n",
    "    def plot_quality_radar(self, quality_data):\n",
    "        \"\"\"Create radar chart for quality metrics\"\"\"\n",
    "        metrics = list(quality_data.keys())\n",
    "        values = [np.mean(quality_data[metric]) * 100 for metric in metrics]\n",
    "        \n",
    "        # Create radar chart\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values + [values[0]],  # Close the polygon\n",
    "            theta=metrics + [metrics[0]],\n",
    "            fill='toself',\n",
    "            name='Quality Scores',\n",
    "            line_color='cyan'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(\n",
    "                    visible=True,\n",
    "                    range=[0, 100]\n",
    "                )),\n",
    "            title=\"Visualization Quality Metrics\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "    \n",
    "    def analyze_lod_quality_impact(self):\n",
    "        \"\"\"Analyze how LOD affects visualization quality\"\"\"\n",
    "        lod_quality_impact = {}\n",
    "        \n",
    "        for lod in config['lod_levels']:\n",
    "            # Simulate quality degradation with higher LOD\n",
    "            base_quality = 0.95 - (lod * 0.05)\n",
    "            quality_scores = np.random.normal(base_quality, 0.02, 50)\n",
    "            lod_quality_impact[f'LOD_{lod}'] = quality_scores\n",
    "        \n",
    "        # Create comparison plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        positions = range(len(config['lod_levels']))\n",
    "        quality_data = [lod_quality_impact[f'LOD_{lod}'] for lod in config['lod_levels']]\n",
    "        \n",
    "        bp = ax.boxplot(quality_data, positions=positions, patch_artist=True)\n",
    "        \n",
    "        colors = ['red', 'yellow', 'green']\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax.set_xticklabels([f'LOD {lod}' for lod in config['lod_levels']])\n",
    "        ax.set_ylabel('Quality Score', color='white')\n",
    "        ax.set_title('Visualization Quality by LOD Level', color='white')\n",
    "        ax.tick_params(colors='white')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return lod_quality_impact\n",
    "\n",
    "# Run quality analysis\n",
    "quality_analyzer = QualityAnalyzer()\n",
    "quality_data = quality_analyzer.simulate_quality_metrics()\n",
    "quality_analyzer.plot_quality_radar(quality_data)\n",
    "lod_quality = quality_analyzer.analyze_lod_quality_impact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492579f0",
   "metadata": {},
   "source": [
    "## Interactive Performance Dashboard\n",
    "\n",
    "Create interactive visualizations for real-time performance monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive dashboard for real-time monitoring\n",
    "from IPython.widgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def create_interactive_dashboard():\n",
    "    \"\"\"Create interactive performance dashboard\"\"\"\n",
    "    \n",
    "    @interact(\n",
    "        lod_level=widgets.IntSlider(min=0, max=2, step=1, value=1, description='LOD Level:'),\n",
    "        time_window=widgets.IntSlider(min=10, max=100, step=10, value=50, description='Time Window:')\n",
    "    )\n",
    "    def update_dashboard(lod_level, time_window):\n",
    "        lod_key = f'lod_{lod_level}'\n",
    "        data = sample_data[lod_key]\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f'Real-time Performance Dashboard - LOD {lod_level}', fontsize=16, color='white')\n",
    "        \n",
    "        # FPS over time\n",
    "        fps_sample = data['fps'][:time_window]\n",
    "        ax1.plot(fps_sample, color='cyan', linewidth=2)\n",
    "        ax1.axhline(y=config['target_fps'], color='red', linestyle='--', label='Target')\n",
    "        ax1.axhline(y=config['acceptable_fps'], color='orange', linestyle='--', label='Min Acceptable')\n",
    "        ax1.set_title('FPS Over Time', color='white')\n",
    "        ax1.set_ylabel('FPS', color='white')\n",
    "        ax1.legend()\n",
    "        ax1.tick_params(colors='white')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Frame time histogram\n",
    "        frame_times = data['frame_time'][:time_window]\n",
    "        ax2.hist(frame_times, bins=20, alpha=0.7, color='green', edgecolor='white')\n",
    "        ax2.set_title('Frame Time Distribution', color='white')\n",
    "        ax2.set_xlabel('Frame Time (ms)', color='white')\n",
    "        ax2.set_ylabel('Frequency', color='white')\n",
    "        ax2.tick_params(colors='white')\n",
    "        \n",
    "        # Memory usage\n",
    "        memory_sample = data['memory_usage'][:time_window]\n",
    "        ax3.plot(memory_sample, color='magenta', linewidth=2)\n",
    "        ax3.set_title('Memory Usage', color='white')\n",
    "        ax3.set_ylabel('Memory (MB)', color='white')\n",
    "        ax3.tick_params(colors='white')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Point count vs FPS scatter\n",
    "        points_sample = data['point_count'][:time_window]\n",
    "        ax4.scatter(points_sample, fps_sample, alpha=0.6, color='yellow')\n",
    "        ax4.set_title('Points vs FPS', color='white')\n",
    "        ax4.set_xlabel('Point Count', color='white')\n",
    "        ax4.set_ylabel('FPS', color='white')\n",
    "        ax4.tick_params(colors='white')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display key statistics\n",
    "        print(f\"\\\\n=== Performance Summary for LOD {lod_level} ===\")\n",
    "        print(f\"Average FPS: {np.mean(fps_sample):.2f}\")\n",
    "        print(f\"Min FPS: {np.min(fps_sample):.2f}\")\n",
    "        print(f\"Max FPS: {np.max(fps_sample):.2f}\")\n",
    "        print(f\"Average Frame Time: {np.mean(frame_times):.2f}ms\")\n",
    "        print(f\"Average Points: {np.mean(points_sample):,.0f}\")\n",
    "        print(f\"Average Memory: {np.mean(memory_sample):.1f}MB\")\n",
    "        print(f\"Target FPS Compliance: {np.mean(fps_sample >= config['target_fps']) * 100:.1f}%\")\n",
    "\n",
    "# Create the dashboard\n",
    "create_interactive_dashboard()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
